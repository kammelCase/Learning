{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef08ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jon, probably disregard this!\n",
    "\n",
    "# making this cheat sheet for myself\n",
    "# contains info that i want to retain better\n",
    "# but not really info that i already know very well\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626531eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape\n",
    "\n",
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "df1 = make_df('AB', [1,2])\n",
    "df2 = make_df('AB', [3,4])\n",
    "\n",
    "df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n",
    "                    'food': ['fish', 'beans', 'bread']},\n",
    "                   columns=['name', 'food'])\n",
    "df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],\n",
    "                    'drink': ['wine', 'beer']},\n",
    "                   columns=['name', 'drink'])\n",
    "x1 = np.random.randint(10, size=(3,3,3))\n",
    "titanic = sns.load_dataset('titanic')\n",
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])\n",
    "full_monte = pd.DataFrame({'name': monte,\n",
    "                           'info': ['B|C|D', 'B|D', 'A|C',\n",
    "                                    'B|D', 'B|C', 'B|C|D']})\n",
    "seattle = pd.read_csv('data/Seattle2014.csv')\n",
    "rainfall = np.array(seattle['PRCP'])\n",
    "\n",
    "inches = rainfall/254.0   #1/10mm -> inches\n",
    "x3 = np.random.randint(10, size=(6,6))\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "pop = pd.Series(populations, index=index)\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "index\n",
    "\n",
    "pop = pop.reindex(index)\n",
    "pop\n",
    "ser = pop\n",
    "\n",
    "# example data\n",
    "\n",
    "### hierarchical indices and columns\n",
    "index1 = pd.MultiIndex.from_product([[2013, 2014], [1, 2]],\n",
    "                                   names=['year', 'visit'])\n",
    "columns1 = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],\n",
    "                                     names=['subject', 'type'])\n",
    "\n",
    "# mock some data\n",
    "data = np.round(np.random.randn(4, 6), 1)\n",
    "data[:, ::2] *= 10\n",
    "data += 37\n",
    "\n",
    "### create the DataFrame\n",
    "health_data = pd.DataFrame(data, index=index, columns=columns)\n",
    "health_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc pandas\n",
    "\n",
    "df.insert(0, 'column_name', 'entry');\n",
    "df.memory_usage(deep=true).sum()\n",
    "df.select_dtypes(int)\n",
    "df.astype({'column_name':'int16'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3beca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering array info\n",
    "\n",
    "print('x1 shape is', x1.shape)\n",
    "print('x1 number of dimentions is', x1.ndim)\n",
    "print('x1 number of values is', x1.size)\n",
    "print('x1 size of each value in bytes is', x1.itemsize)\n",
    "print('x1 total size is', x1.size*x1.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f63686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.reduce\n",
    "\n",
    "np.add.reduce(x1)           # reduce by adding\n",
    "np.subtract.reduce(x1)      # reduce by subtraction\n",
    "np.add.accumulate(x1)       # shows steps that go into reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer: in this case, multiplies the two dimentions specified (there doesn't appear to be an inner version of this)\n",
    "\n",
    "x2 = np.arange(1,6)\n",
    "x2 = np.multiply.outer(x2, x2)      # multiplies a list by itself on outter to create a 2d array\n",
    "x2_centered = x2 - x2.mean(axis=0)  # centering data on the row axis\n",
    "np.mean(x2_centered)                # result: 0. used to double check if x2 is indeed centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean arrays\n",
    "\n",
    "inches < 0.25;                              # produces boolean array\n",
    "\n",
    "np.count_nonzero(inches < 0.25)             # counts nonzero values\n",
    "#same as\n",
    "np.sum(inches < 0.25)\n",
    "\n",
    "np.sum((inches > 0.25) & (inches < 1))      # boolean range\n",
    "inches[inches>1]                            # returns all values of True results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting + partitioning\n",
    "\n",
    "np.sort(x3) # sort function\n",
    "np.sort(x3, axis=0) # column sort\n",
    "np.partition(x3, 2, axis=0) #target, amount, axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection\n",
    "\n",
    "df.A  # access column 'A'\n",
    "df['A']  # access column 'A'\n",
    "\n",
    "df.iloc[0]  # access index 0 (implicit)\n",
    "df.iloc[:2,:2]  # access slice (implicit)\n",
    "\n",
    "df.loc[0]  # access index 0 (explicit, but because i[0] is also labeled 0, this is the same as iloc[0])\n",
    "df.loc[:,'A':'C']  # access columns A-C (explicit)\n",
    "\n",
    "df[df.A>6]  # boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull()  -  generate a boolean mask indicating missing values\n",
    "# notnull()  -  opposite of isnull()\n",
    "# dropna()  -  return a filtered version of the data\n",
    "# fillna()  -  return a copy of the data with missing data filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndex\n",
    "\n",
    "ser.unstack()                       # unstack to turn a MultiIndex into a df\n",
    "ser.unstack(0)                      # specifying index level 0 to unstack\n",
    "ser.unstack().stack()               # stack again to go back if you need\n",
    "df.index.names = ['State', 'Year']  # naming the indices of a MultiIndex\n",
    "\n",
    "\n",
    "# ways to explicitly create a MultiIndex\n",
    "# pd.MultiIndex.from_arrays\n",
    "# pd.MultiIndex.from_tuples\n",
    "# pd.MultiIndex.from_product\n",
    "\n",
    "# Selection in Series MultiIndex\n",
    "ser['California']   # easily select any index\n",
    "ser['New York', 2010]   # easily select multiple indices\n",
    "ser['California':'New York']    # slicing is avail as long as MultiIndex is sorted\n",
    "ser[:, 2000]    # access all 2010 entries\n",
    "ser[pop > 200]  # boolean masking\n",
    "\n",
    "# Selection in MultiIndex DFs\n",
    "health_data['Guido']            # columns first, selecting all Guido's results\n",
    "health_data['Guido', 'HR']      # Guido's results, only HR\n",
    "\n",
    "# above: notice how we progress from highest level column index, to lowest level\n",
    "\n",
    "health_data.iloc[:2, :2]        #iloc works as normal\n",
    "\n",
    "# create a pd.IndexSlice variable\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# use variable to slice and select\n",
    "# again, think outside to inside here with indexing\n",
    "health_data.loc[idx[:, 1], idx[:, 'HR']]\n",
    "\n",
    "df = df.sort_index()            # you cannot slice indices that aren't sorted\n",
    "df = df.reset_index()           # create a new, blank, ordered index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d82a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat()\n",
    "\n",
    "pd.concat([df1, df2])   # normal\n",
    "pd.concat([df1, df2], axis=1)   # along columns\n",
    "pd.concat([df1, df2], verify_integrity=True)    # will return error if repeat indices are present\n",
    "pd.concat([df1, df2], keys=['A', 'B'])          # create new keys as indexes\n",
    "pd.concat([df1, df2], join='inner')             # only intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b585be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by column method\n",
    "# show column orbital_period\n",
    "# show median results\n",
    "\n",
    "planets.groupby('method')['orbital_period'].mean()      # also median()\n",
    "planets.groupby('method')['orbital_period'].count()\n",
    "planets.groupby('method')['orbital_period'].first()     # also last()\n",
    "planets.groupby('method')['orbital_period'].min()       # also max()\n",
    "planets.groupby('method')['orbital_period'].std()       # also var()\n",
    "planets.groupby('method')['orbital_period'].sum()\n",
    "\n",
    "# why not go big?\n",
    "planets.groupby('method')['orbital_period'].describe()\n",
    "\n",
    "# can also groupby on the index levels\n",
    "# planets.groupby(level=0)['distance_ft'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc11d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge()\n",
    "\n",
    "pd.merge(df6, df7)\n",
    "pd.merge(df6, df7, how='outer')     # show all results (default is inner)\n",
    "pd.merge(df6, df7, how='left')      # show column results for left (df6)\n",
    "pd.merge(df6, df7, on='name')       # use as key\n",
    "pd.merge(df6, df7, left_index=True, right_index=True)   # can be mixed and match with left_on and right_on too!\n",
    "pd.merge(df6, df7, left_on='name', right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a721dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table()\n",
    "\n",
    "titanic.pivot_table('survived', index='sex', columns='class')   # 2d pivot table\n",
    "titanic.pivot_table('survived', ['sex', age], [fare, 'class'])  # 4d pivot table\n",
    "titanic.pivot_table(index='sex', columns='class', \n",
    "                    aggfunc={'survived':sum, 'fare':'mean'})    # pivot table with various aggfuncs on columns\n",
    "titanic.pivot_table('survived', index='sex', \n",
    "                    columns='class', margins=True)              # margins= for grouping totals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f97961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings in pandas\n",
    "\n",
    "monte.str.cotains('string')     # returns all results containing string\n",
    "\n",
    "spotify.loc[spotify['track_name'].str.contains('roxanne', case=False, regex=True)]\n",
    "\n",
    "monte.str.capitalize()          # .str to access string fuctions\n",
    "monte.str.split()               # .split() to split up words between spaces\n",
    "monte.str.extract('([A-Za-z]+)', expand=False)  # return first names\n",
    "monte.str.findall(r'^[^AEIOU].*[^aeiou]$')      # findall() return names that start and end with a consonant\n",
    "monte.str.slice(start=0, stop=3)    # return first three letters of entire list\n",
    "full_monte['info'].str.get_dummies('|')     # separate out dummies and make new df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c35c5",
   "metadata": {},
   "source": [
    "### Methods similar to Python string methods\n",
    "Nearly all Python's built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas ``str`` methods that mirror Python string methods:\n",
    "\n",
    "|             |                  |                  |                  |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n",
    "Notice that these have various return values. Some, like ``lower()``, return a series of strings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee03c5",
   "metadata": {},
   "source": [
    "### Miscellaneous methods\n",
    "Finally, there are some miscellaneous methods that enable other convenient operations:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``get()`` | Index each element |\n",
    "| ``slice()`` | Slice each element|\n",
    "| ``slice_replace()`` | Replace slice in each element with passed value|\n",
    "| ``cat()``      | Concatenate strings|\n",
    "| ``repeat()`` | Repeat values |\n",
    "| ``normalize()`` | Return Unicode form of string |\n",
    "| ``pad()`` | Add whitespace to left, right, or both sides of strings|\n",
    "| ``wrap()`` | Split long strings into lines with length less than a given width|\n",
    "| ``join()`` | Join strings in each element of the Series with passed separator|\n",
    "| ``get_dummies()`` | extract dummy variables as a dataframe |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5fd61",
   "metadata": {},
   "source": [
    "### Methods similar to Python string methods\n",
    "Nearly all Python's built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas ``str`` methods that mirror Python string methods:\n",
    "\n",
    "|             |                  |                  |                  |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n",
    "Notice that these have various return values. Some, like ``lower()``, return a series of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in pandas\n",
    "\n",
    "date = pd.to_datetime('4th of july, 2012')  # result: Timestamp('2012-07-04 00:00:00')\n",
    "date + pd.to_timedelta(np.arange(12), 'h')  # h for hour\n",
    "lebron['date'] = pd.to_datetime(lebron['date'], format='%Y-%m-%d')  # converting date column to datetime format\n",
    "lebron['date'].min()    # viewing the earliest date\n",
    "lebron['date'].max()    # viewing the most recent date\n",
    "lebron['date'].max() - lebron['date'].min() # getting time delta between two days\n",
    "filt = (lebron['date'] >= '05-18-2023') # creating filter for timeframe\n",
    "lebron.loc[filt]    # using filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
