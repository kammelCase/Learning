{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to incorporate some ml stuff to this nba data now, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26549da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lebron = pd.read_csv('data/NBA/1_lebron_james_shot_chart_1_2023.csv')\n",
    "james = pd.read_csv('data/NBA/2_james_harden_shot_chart_2023.csv')\n",
    "stephen = pd.read_csv('data/NBA/3_stephen_curry_shot_chart_2023.csv')\n",
    "\n",
    "print(lebron.shape)\n",
    "print(james.shape)\n",
    "print(stephen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lebron.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to use the positional data from 'top' and 'left' to create a \n",
    "# model that predicts whether lebron james will make a shot or not\n",
    "\n",
    "# first let's select the top and left columns for X_train\n",
    "# and shots made for the y_train\n",
    "\n",
    "X_train = lebron.iloc[0:1300,0:2].to_numpy().astype('int16')\n",
    "y_train = lebron.iloc[0:1300,5].to_numpy().astype('int8')\n",
    "\n",
    "X_valid = lebron.iloc[1300:1533,0:2].to_numpy().astype('int16')\n",
    "y_valid = lebron.iloc[1300:1533,5].to_numpy().astype('int8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adder = lebron.iloc[0:1300,7].to_numpy().astype('int16')\n",
    "X_train = np.concatenate((X_train, X_train_adder.reshape(-1,1)), axis=1)\n",
    "X_train\n",
    "\n",
    "X_valid_adder = lebron.iloc[1300:1533,7].to_numpy().astype('int16')\n",
    "X_valid = np.concatenate((X_valid, X_valid_adder.reshape(-1,1)), axis=1)\n",
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's scale the data\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to create a model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# creating initialization variable\n",
    "init = tf.keras.initializers.RandomNormal(mean=0., stddev=1., seed=None)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation='relu', input_shape=[3]),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into AlexNet in regards to MNIST\n",
    "# builing different models\n",
    "# write a python script that saves the network at it's maximum accuracy\n",
    "# write a python script that stops training when the network stops improving\n",
    "# also save the state of the model at it's maximum accuracy\n",
    "# look into ResNet in regards to MNIST\n",
    "\n",
    "# try to achieve 99% accuracy on MNIST without changing the network architecture\n",
    "\n",
    "# look into flattening\n",
    "\n",
    "# look into softmax\n",
    "\n",
    "# get MNIST to 99% accuracy\n",
    "\n",
    "# spanning pooling pyramids\n",
    "\n",
    "# convulational layer\n",
    "# frozen layer\n",
    "# dense layer\n",
    "# softmax layer\n",
    "\n",
    "# what's a memory leak?\n",
    "\n",
    "# refresher on CS101 stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
