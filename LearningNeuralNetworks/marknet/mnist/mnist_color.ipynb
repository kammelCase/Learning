{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Using 8000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    'data/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size=(28, 28),\n",
    "    seed=132,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate train_ds into X_train and y_train\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for image in images:\n",
    "        X_train.append(image)\n",
    "    for label in labels:\n",
    "        y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Using 2000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    'data/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size=(28, 28),\n",
    "    seed=132,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# checking class names\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# checking shape of data\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# # Assume `x_train` and `y_train` are your training images and labels\n",
    "\n",
    "# # Define the data augmentation\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#   preprocessing.Rescaling(1./255),\n",
    "#   preprocessing.RandomRotation(0.1),\n",
    "#   preprocessing.RandomContrast(0.5),\n",
    "# ])\n",
    "\n",
    "# # Create empty lists to hold the augmented images and labels\n",
    "# x_train_augmented = []\n",
    "# y_train_augmented = []\n",
    "\n",
    "# # For each image in the training set\n",
    "# for x, y in zip(train_X, train_y):\n",
    "#     # Create 5 augmented versions of the image\n",
    "#     for _ in range(2):\n",
    "#         augmented_image = data_augmentation(tf.expand_dims(x, 0), training=True)\n",
    "#         x_train_augmented.append(tf.squeeze(augmented_image).numpy())\n",
    "#         y_train_augmented.append(y)\n",
    "\n",
    "# # Convert the lists to numpy arrays\n",
    "# x_train_augmented = np.array(x_train_augmented)\n",
    "# y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure for performance\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize layer\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    keras.layers.RandomBrightness(0.1),\n",
    "    keras.layers.RandomRotation(0.1),\n",
    "    keras.layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building our model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # augmentation,\n",
    "  normalization_layer,\n",
    "\n",
    "  keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "  keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  keras.layers.Dropout(0.2),\n",
    "\n",
    "  keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "  keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "  keras.layers.Dropout(0.2),  \n",
    "\n",
    "  tf.keras.layers.Flatten(),\n",
    "  keras.layers.Dropout(0.2),\n",
    "\n",
    "  tf.keras.layers.Dense(40, activation='relu'),\n",
    "  tf.keras.layers.Dense(40, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile (\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_callbacks = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.0499 - accuracy: 0.6284 - val_loss: 0.2557 - val_accuracy: 0.9200\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.2598 - accuracy: 0.9183 - val_loss: 0.1715 - val_accuracy: 0.9455\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.1828 - accuracy: 0.9417 - val_loss: 0.1322 - val_accuracy: 0.9585\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.1527 - accuracy: 0.9485 - val_loss: 0.1270 - val_accuracy: 0.9610\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.1248 - accuracy: 0.9581 - val_loss: 0.0968 - val_accuracy: 0.9675\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.1019 - accuracy: 0.9649 - val_loss: 0.0884 - val_accuracy: 0.9740\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0978 - accuracy: 0.9674 - val_loss: 0.0936 - val_accuracy: 0.9705\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0772 - accuracy: 0.9744 - val_loss: 0.0786 - val_accuracy: 0.9790\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.0760 - accuracy: 0.9758 - val_loss: 0.0744 - val_accuracy: 0.9805\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.0777 - accuracy: 0.9745 - val_loss: 0.0677 - val_accuracy: 0.9775\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.0635 - accuracy: 0.9787 - val_loss: 0.0601 - val_accuracy: 0.9825\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0615 - accuracy: 0.9783 - val_loss: 0.0606 - val_accuracy: 0.9835\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 0.0768 - val_accuracy: 0.9775\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0534 - accuracy: 0.9809 - val_loss: 0.0610 - val_accuracy: 0.9840\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0540 - accuracy: 0.9799 - val_loss: 0.0712 - val_accuracy: 0.9815\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0490 - accuracy: 0.9827 - val_loss: 0.0617 - val_accuracy: 0.9840\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0490 - accuracy: 0.9834 - val_loss: 0.0572 - val_accuracy: 0.9830\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 0.0712 - val_accuracy: 0.9830\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.0564 - val_accuracy: 0.9825\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0390 - accuracy: 0.9870 - val_loss: 0.0625 - val_accuracy: 0.9830\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0316 - accuracy: 0.9885 - val_loss: 0.0619 - val_accuracy: 0.9820\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.0669 - val_accuracy: 0.9835\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0716 - val_accuracy: 0.9815\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.0540 - val_accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0721 - val_accuracy: 0.9845\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0565 - val_accuracy: 0.9870\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.0695 - val_accuracy: 0.9860\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.0648 - val_accuracy: 0.9815\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 0.0718 - val_accuracy: 0.9830\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0289 - accuracy: 0.9901 - val_loss: 0.0562 - val_accuracy: 0.9845\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.1062 - val_accuracy: 0.9755\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.9835\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0726 - val_accuracy: 0.9840\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0824 - val_accuracy: 0.9825\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0648 - val_accuracy: 0.9835\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9916Restoring model weights from the end of the best epoch: 26.\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.0628 - val_accuracy: 0.9845\n",
      "Epoch 36: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17587c050>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[all_callbacks],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.002760360948741436\n",
      "Test accuracy: 0.9991250038146973\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 16 - no standardization, no augmentation - 97.2% accuracy\n",
    "# Somehow achieved 99.7% accuracy on test set, which i didn't expect, investigating...\n",
    "# Now 99.91 which feels sorta impossible. Investigating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assume `data_augmentation` is your Sequential model containing the data augmentation layers\n",
    "# # Assume `x_train` is your training data\n",
    "\n",
    "# # Choose the first image from the training data\n",
    "# image = train_X[0]\n",
    "\n",
    "# # Apply the data augmentation to the image 5 times\n",
    "# augmented_images = [data_augmentation(tf.expand_dims(image, 0), training=True) for _ in range(5)]\n",
    "\n",
    "# # Remove the extra dimension added by tf.expand_dims\n",
    "# augmented_images = [tf.squeeze(img).numpy() for img in augmented_images]\n",
    "\n",
    "# # Plot the original image and the augmented images\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(6):\n",
    "#     ax = plt.subplot(3, 2, i + 1)\n",
    "#     if i == 0:\n",
    "#         plt.imshow(image)\n",
    "#         plt.title(\"Original image\")\n",
    "#     else:\n",
    "#         plt.imshow(augmented_images[i - 1])\n",
    "#         plt.title(f\"Augmented image {i}\")\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
