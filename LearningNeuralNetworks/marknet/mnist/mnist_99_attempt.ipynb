{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the mnist dataset and split it into train and test\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming shape of X\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing X by 255 to return a value between 0 and 1, as 255 is the max rgb value of each pixel\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure images have shape (28, 28, 1)\n",
    "# jon, help here. this doesn't make sense to me yet.\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y to one-hot encoding\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# confirming shapes again\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras documentation network\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Input(shape=(28,28,1)),\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "#     keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_5\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_5/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_5/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_5\" (type Conv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# inspired by vgg16\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m16\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m,\u001b[39m1\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m16\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.5\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m40\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m40\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m10\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_attempt.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m ])\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1021\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1018\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1019\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1020\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1021\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[1;32m   1023\u001b[0m \u001b[39m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[39m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m extract_traceback:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_5\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_5/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_5/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_5\" (type Conv2D):\n  â€¢ inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# inspired by vgg16\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(40, activation='relu'),\n",
    "    keras.layers.Dense(40, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building my own AlexNet\n",
    "\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.LayerNormalization(),\n",
    "\n",
    "#     keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.LayerNormalization(),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "\n",
    "#     keras.layers.Dense(50, activation='relu'),\n",
    "#     keras.layers.Dense(50, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a convolutional neural net, as this works best with image classifiers\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.Dropout(0.25),\n",
    "\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.Dropout(0.25),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphing training\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8,5), xlim=[0,29], ylim=[0,1], grid=True, xlabel='Epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reults with keras documentation network: 99.2\n",
    "# results with AlexNet v1 (50x50 dense): 99.0\n",
    "# results with AlexNet v1 (100x100 dense): 98.9\n",
    "# results with AlexNet v1 (25x25 dense): 98.6\n",
    "# results with VGG16 style: 99.40"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
