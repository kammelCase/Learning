{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Using 8000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    'data/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size=(28, 28),\n",
    "    seed=132,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = Image.open('data/0/blue_10.png')\n",
    "draw = ImageDraw.Draw(test_img)\n",
    "\n",
    "draw.ellipse((8,8,18,18), fill=(10,10,10,10), \n",
    "                outline=\"black\", width=25)\n",
    "\n",
    "test_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     draw\u001b[39m.\u001b[39mellipse((\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m18\u001b[39m,\u001b[39m18\u001b[39m), fill\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                 outline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m src_img \u001b[39min\u001b[39;00m source_folder:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     img1 \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(src_img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     img1 \u001b[39m=\u001b[39m filter1(src_img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     img1\u001b[39m.\u001b[39msave(dest_folder)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/PIL/Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3215\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3217\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3218\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3219\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd'"
     ]
    }
   ],
   "source": [
    "source_folder = 'data/'\n",
    "dest_folder = 'data5x/'\n",
    "\n",
    "def filter1(img):\n",
    "    img = ImageDraw.Draw(test_img)\n",
    "    draw.ellipse((8,8,18,18), fill=(10,10,10,10), \n",
    "                outline=\"black\", width=25)\n",
    "\n",
    "for src_img in source_folder:\n",
    "    img1 = Image.open(src_img)\n",
    "    img1 = filter1(src_img)\n",
    "    img1.save(dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m src_img \u001b[39min\u001b[39;00m source_folder:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     img1 \u001b[39m=\u001b[39m splotch(src_img)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     save(img1 , source_folder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save' is not defined"
     ]
    }
   ],
   "source": [
    "source_folder = '/data/'\n",
    "dest_folder = '/data5x/'\n",
    "\n",
    "def splotch(img):\n",
    "    img = 1\n",
    "\n",
    "\n",
    "for src_img in source_folder:\n",
    "    img1 = splotch(src_img)\n",
    "    save(img1 , source_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate train_ds into X_train and y_train\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for image in images:\n",
    "        X_train.append(image)\n",
    "    for label in labels:\n",
    "        y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    'data/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size=(28, 28),\n",
    "    seed=132,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class names\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize layer\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Assume `x_train` and `y_train` are your training images and labels\n",
    "\n",
    "# Define the data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  preprocessing.Rescaling(1./255),\n",
    "  preprocessing.RandomRotation(0.1),\n",
    "  preprocessing.RandomContrast(0.5),\n",
    "])\n",
    "\n",
    "# Create empty lists to hold the augmented images and labels\n",
    "x_train_augmented = []\n",
    "y_train_augmented = []\n",
    "\n",
    "# For each image in the training set\n",
    "for x, y in zip(train_X, train_y):\n",
    "    # Create 5 augmented versions of the image\n",
    "    for _ in range(2):\n",
    "        augmented_image = data_augmentation(tf.expand_dims(x, 0), training=True)\n",
    "        x_train_augmented.append(tf.squeeze(augmented_image).numpy())\n",
    "        y_train_augmented.append(y)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_train_augmented = np.array(x_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure for performance\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building our model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # normalization_layer,\n",
    "\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  \n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(40, activation='relu'),\n",
    "  tf.keras.layers.Dense(40, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile (\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_callbacks = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train_augmented,\n",
    "    y_train_augmented,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[all_callbacks],\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume `data_augmentation` is your Sequential model containing the data augmentation layers\n",
    "# Assume `x_train` is your training data\n",
    "\n",
    "# Choose the first image from the training data\n",
    "image = train_X[0]\n",
    "\n",
    "# Apply the data augmentation to the image 5 times\n",
    "augmented_images = [data_augmentation(tf.expand_dims(image, 0), training=True) for _ in range(5)]\n",
    "\n",
    "# Remove the extra dimension added by tf.expand_dims\n",
    "augmented_images = [tf.squeeze(img).numpy() for img in augmented_images]\n",
    "\n",
    "# Plot the original image and the augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(3, 2, i + 1)\n",
    "    if i == 0:\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Original image\")\n",
    "    else:\n",
    "        plt.imshow(augmented_images[i - 1])\n",
    "        plt.title(f\"Augmented image {i}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
