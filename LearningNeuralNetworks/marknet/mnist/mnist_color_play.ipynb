{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Using 8000 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    'data/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size=(28, 28),\n",
    "    seed=132,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with drawing an ellipse on an mnist image\n",
    "# works!\n",
    "\n",
    "test_img = Image.open('data/0/blue_10.png')\n",
    "draw = ImageDraw.Draw(test_img)\n",
    "\n",
    "draw.ellipse((8,8,18,18), fill=(10,10,10,10), \n",
    "                outline=\"black\", width=25)\n",
    "\n",
    "test_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m testing \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata/0/blue_10.png\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m testing \u001b[39m=\u001b[39m filter1(testing)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_color_play.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m testing\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "# no success here :(\n",
    "\n",
    "source_folder = 'data/'\n",
    "dest_folder = 'data5x/'\n",
    "\n",
    "def filter1(img):\n",
    "    img = Image.open(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    img =  draw.ellipse((8,8,18,18), fill=(10,10,10,10), \n",
    "                outline=\"black\", width=25)\n",
    "    return img\n",
    "\n",
    "testing = 'data/0/blue_10.png'\n",
    "testing = filter1(testing)\n",
    "\n",
    "testing.show()\n",
    "\n",
    "# for src_img in source_folder:\n",
    "#     img1 = Image.open(src_img)\n",
    "#     img1 = filter1(img1)\n",
    "#     img1.save(dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'data/'\n",
    "dest_folder = 'data5x/'\n",
    "\n",
    "img = Image.open('data/0/blue_10.png')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for src_img in source_folder:\n",
    "    draw.ellipse((8,8,18,18), fill=(10,10,10,10), \n",
    "                outline=\"black\", width=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '/data/'\n",
    "dest_folder = '/data5x/'\n",
    "\n",
    "def splotch(img):\n",
    "    img = 1\n",
    "\n",
    "\n",
    "for src_img in source_folder:\n",
    "    img1 = splotch(src_img)\n",
    "    save(img1 , source_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's separate train_ds into X_train and y_train\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for image in images:\n",
    "        X_train.append(image)\n",
    "    for label in labels:\n",
    "        y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    'data/',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size=(28, 28),\n",
    "    seed=132,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class names\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize layer\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Assume `x_train` and `y_train` are your training images and labels\n",
    "\n",
    "# Define the data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  preprocessing.Rescaling(1./255),\n",
    "  preprocessing.RandomRotation(0.1),\n",
    "  preprocessing.RandomContrast(0.5),\n",
    "])\n",
    "\n",
    "# Create empty lists to hold the augmented images and labels\n",
    "x_train_augmented = []\n",
    "y_train_augmented = []\n",
    "\n",
    "# For each image in the training set\n",
    "for x, y in zip(train_X, train_y):\n",
    "    # Create 5 augmented versions of the image\n",
    "    for _ in range(2):\n",
    "        augmented_image = data_augmentation(tf.expand_dims(x, 0), training=True)\n",
    "        x_train_augmented.append(tf.squeeze(augmented_image).numpy())\n",
    "        y_train_augmented.append(y)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_train_augmented = np.array(x_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure for performance\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building our model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # normalization_layer,\n",
    "\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  \n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(40, activation='relu'),\n",
    "  tf.keras.layers.Dense(40, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile (\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_callbacks = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train_augmented,\n",
    "    y_train_augmented,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[all_callbacks],\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume `data_augmentation` is your Sequential model containing the data augmentation layers\n",
    "# Assume `x_train` is your training data\n",
    "\n",
    "# Choose the first image from the training data\n",
    "image = train_X[0]\n",
    "\n",
    "# Apply the data augmentation to the image 5 times\n",
    "augmented_images = [data_augmentation(tf.expand_dims(image, 0), training=True) for _ in range(5)]\n",
    "\n",
    "# Remove the extra dimension added by tf.expand_dims\n",
    "augmented_images = [tf.squeeze(img).numpy() for img in augmented_images]\n",
    "\n",
    "# Plot the original image and the augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(3, 2, i + 1)\n",
    "    if i == 0:\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Original image\")\n",
    "    else:\n",
    "        plt.imshow(augmented_images[i - 1])\n",
    "        plt.title(f\"Augmented image {i}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
