{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the mnist dataset and split it into train and test\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a pre-processing image augmentation layer that plugs directly into model\n",
    "\n",
    "# data_augmentation = keras.Sequential(\n",
    "#   [\n",
    "#     keras.layers.RandomFlip(\"horizontal\", input_shape=(28,28,1)),\n",
    "#     keras.layers.RandomRotation(0.1),\n",
    "#     keras.layers.RandomZoom(0.1),\n",
    "#   ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a tf.data pipeline of augmented images (and their labels)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# train_dataset = train_dataset.batch(16).map(lambda x, y: (data_augmentation(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming shape of X\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing X by 255 to return a value between 0 and 1, as 255 is the max rgb value of each pixel\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure images have shape (28, 28, 1)\n",
    "# \n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y to one-hot encoding\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# confirming shapes again\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras documentation network\n",
    "\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Input(shape=(28,28,1)),\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "#     keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found online\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', strides=1, padding='same', data_format='channels_last', input_shape=(28,28,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', strides=1, padding='same', data_format='channels_last'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "\n",
    "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', strides=1, padding='same', data_format='channels_last'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', strides=1, padding='same', data_format='channels_last'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    # keras.layers.MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),\n",
    "    # tinker with pool_size, also look at other parameters\n",
    "    # keras.layers.Dropout(0.25),\n",
    "\n",
    "    # keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inspired by vgg16\n",
    "\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     # data_augmentation,\n",
    "#     keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "\n",
    "#     keras.layers.Dense(40, activation='relu'),\n",
    "#     keras.layers.Dense(40, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # building my own AlexNet\n",
    "\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.LayerNormalization(),\n",
    "\n",
    "#     keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.LayerNormalization(),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "\n",
    "#     keras.layers.Dense(50, activation='relu'),\n",
    "#     keras.layers.Dense(50, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a convolutional neural net, as this works best with image classifiers\n",
    "\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.Dropout(0.25),\n",
    "\n",
    "#     keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "#     keras.layers.Dropout(0.25),\n",
    "\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 28, 28, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28, 28, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14, 14, 512)       8704      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 14, 14, 512)       2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14, 14, 1024)      525312    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 14, 14, 1024)      4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14, 14, 10)        10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557786 (2.13 MB)\n",
      "Trainable params: 554586 (2.12 MB)\n",
      "Non-trainable params: 3200 (12.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.003)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding callback to stop training after validation_loss or validation_accuracy stop increasing with patience = 6\n",
    "\n",
    "callback_val_loss = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    ")\n",
    "\n",
    "callback_val_accuracy = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"vall_accuracy\",\n",
    "    patience=6,\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 14, 14, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39m[callback_val_loss, reduce_lr],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     validation_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mark/Desktop/softs/Learning/LearningNeuralNetworks/marknet/mnist/mnist_99_55_accuracy.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/5x/1n063tsx6jx9wzcy34jzlqzh0000gn/T/__autograph_generated_filecp_gce4p.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/mark/anaconda3/envs/ds/lib/python3.11/site-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 14, 14, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[callback_val_loss, reduce_lr],\n",
    "                    validation_split=0.1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reults with keras documentation network: 99.2\n",
    "# results with AlexNet v1 (50x50 dense): 99.0\n",
    "# results with AlexNet v1 (100x100 dense): 98.9\n",
    "# results with AlexNet v1 (25x25 dense): 98.6\n",
    "# results with VGG16 style: 99.41 (loss 0.018311500549316406)\n",
    "\n",
    "# VGG16 style after adding callbacks (99.55)\n",
    "# random online person (99.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
